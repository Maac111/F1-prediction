{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, activations, losses, Model, Input\n",
    "from tensorflow.nn import leaky_relu\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from tensorflow.keras.utils import plot_model, Progbar\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.config.threading.set_intra_op_parallelism_threads(4)\n",
    "# model architecture\n",
    "class RankNet(Model):\n",
    "    def __init__(self):\n",
    "        super(RankNet, self).__init__()\n",
    "        self.dense1 = layers.Dense(16, activation=leaky_relu)\n",
    "        self.dense2 = layers.Dense(8, activation=leaky_relu)\n",
    "        self.o = layers.Dense(1)\n",
    "        self.subtract = layers.Subtract()\n",
    "        self.activation = layers.Activation('sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        xi, xj = inputs\n",
    "        densei = self.dense1(xi)\n",
    "        densej = self.dense1(xj)\n",
    "        densei = self.dense2(densei)\n",
    "        densej = self.dense2(densej)\n",
    "        oi = self.o(densei)\n",
    "        oj = self.o(densej)\n",
    "        oij = self.subtract([oi, oj])\n",
    "        output = self.activation(oij)\n",
    "        return output\n",
    "\n",
    "    def build_graph(self):\n",
    "        x = [Input(shape=(169)), Input(shape=(169))]\n",
    "        return Model(inputs=x, outputs=self.call(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "model_df = pd.read_excel(\"model_df.xlsx\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 900,  901,  902,  903,  904,  905,  906,  907,  908,  909,  910,\n",
       "        911,  912,  913,  914,  915,  916,  917,  918,  926,  927,  928,\n",
       "        929,  930,  931,  932,  933,  934,  936,  937,  938,  939,  940,\n",
       "        941,  942,  943,  944,  945,  948,  949,  950,  951,  952,  953,\n",
       "        954,  955,  956,  957,  958,  959,  960,  961,  962,  963,  964,\n",
       "        965,  966,  967,  968,  969,  970,  971,  972,  973,  974,  975,\n",
       "        976,  977,  978,  979,  980,  981,  982,  983,  984,  985,  986,\n",
       "        987,  988,  989,  990,  991,  992,  993,  994,  995,  996,  997,\n",
       "        998,  999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008,\n",
       "       1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019,\n",
       "       1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1031, 1028, 1029,\n",
       "       1030, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041,\n",
       "       1042, 1043, 1044, 1045, 1046, 1047, 1052, 1053, 1054, 1055, 1056,\n",
       "       1057, 1059, 1058, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067,\n",
       "       1069, 1070, 1071, 1051, 1072, 1073, 1074, 1075, 1076, 1077, 1078,\n",
       "       1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089,\n",
       "       1091, 1092, 1093, 1094, 1095, 1096, 1098, 1099, 1100, 1101, 1102,\n",
       "       1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114,\n",
       "       1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125,\n",
       "       1126], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df[\"raceId\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2157, 169)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate data\n",
    "nb_query = len(model_df[\"raceId\"].unique())\n",
    "### in each query number of docs can be diffrent\n",
    "query = model_df[\"raceId\"].to_numpy()\n",
    "### for each doc we can take some random features\n",
    "temp_data = model_df.drop([\"time\", \"end_position\", \"raceId\"], axis = 1)\n",
    "# doc_scores = []\n",
    "# for q in range(nb_query):\n",
    "#     query_idx = np.where(query == q)[0]\n",
    "#     temp = temp_data.iloc[query_idx,:].values.tolist()\n",
    "#     doc_scores.append(temp)\n",
    "\n",
    "doc_scores = model_df[\"end_position\"].values\n",
    "doc_features = temp_data.values\n",
    "\n",
    "doc_features.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# put data into pairs\n",
    "xi = []\n",
    "xj = []\n",
    "pij = []\n",
    "pair_id = []\n",
    "pair_query_id = []\n",
    "### for each query we must create all pairs\n",
    "for q in np.unique(query):\n",
    "    query_idx = np.where(query == q)[0]\n",
    "    # print(query_idx)\n",
    "    for pair_idx in combinations(query_idx, 2):\n",
    "        pair_query_id.append(q)\n",
    "        \n",
    "        pair_id.append(pair_idx)\n",
    "        i = pair_idx[0]\n",
    "        j = pair_idx[1]\n",
    "        xi.append(doc_features[i]) # features of first doc in pair\n",
    "        xj.append(doc_features[j]) # features of second doc in pair\n",
    "        \n",
    "        \n",
    "        if doc_scores[i] == doc_scores[j]:\n",
    "            _pij = 0.5\n",
    "        elif doc_scores[i] > doc_scores[j]:\n",
    "            _pij = 1\n",
    "        else: \n",
    "            _pij = 0\n",
    "        pij.append(_pij)\n",
    "        \n",
    "xi = np.array(xi)\n",
    "xj = np.array(xj)\n",
    "pij = np.array(pij)\n",
    "pair_query_id = np.array(pair_query_id)\n",
    "\n",
    "xi_train, xi_test, xj_train, xj_test, pij_train, pij_test, pair_id_train, pair_id_test = train_test_split(\n",
    "    xi, xj, pij, pair_id, test_size=0.2, stratify=pair_query_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.01400000e+03, -2.67355573e-01,  1.38843029e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.50000000e+01],\n",
       "       [ 2.01400000e+03, -2.67355573e-01,  1.38843029e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.50000000e+01],\n",
       "       [ 2.01400000e+03, -2.67355573e-01,  1.38843029e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.50000000e+01],\n",
       "       ...,\n",
       "       [ 2.02400000e+03, -1.98885409e+00, -1.29564712e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.26000000e+02],\n",
       "       [ 2.02400000e+03, -1.98885409e+00, -1.29564712e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.26000000e+02],\n",
       "       [ 2.02400000e+03, -1.02446767e+00, -4.26158632e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.26000000e+02]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.4452 - val_loss: 0.3752\n",
      "Epoch 2/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3898 - val_loss: 0.3740\n",
      "Epoch 3/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3888 - val_loss: 0.3730\n",
      "Epoch 4/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3732 - val_loss: 0.3729\n",
      "Epoch 5/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3917 - val_loss: 0.3718\n",
      "Epoch 6/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3863 - val_loss: 0.3724\n",
      "Epoch 7/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3947 - val_loss: 0.3759\n",
      "Epoch 8/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3717 - val_loss: 0.3735\n",
      "Epoch 9/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.3791 - val_loss: 0.3720\n",
      "Epoch 10/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3943 - val_loss: 0.3730\n",
      "Epoch 11/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3865 - val_loss: 0.3718\n",
      "Epoch 12/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3889 - val_loss: 0.3744\n",
      "Epoch 13/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - loss: 0.3947 - val_loss: 0.3723\n",
      "Epoch 14/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3854 - val_loss: 0.3709\n",
      "Epoch 15/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3900 - val_loss: 0.3745\n",
      "Epoch 16/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3784 - val_loss: 0.3730\n",
      "Epoch 17/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3847 - val_loss: 0.3729\n",
      "Epoch 18/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3789 - val_loss: 0.3763\n",
      "Epoch 19/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3730 - val_loss: 0.3740\n",
      "Epoch 20/20\n",
      "\u001b[1m2312/2312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.3802 - val_loss: 0.3774\n"
     ]
    }
   ],
   "source": [
    "# train model using compile and fit\n",
    "\n",
    "ranknet_model = RankNet()\n",
    "ranknet_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "history = ranknet_model.fit([xi_train, xj_train], pij_train, epochs=20, batch_size=4, validation_data=([xi_test, xj_test], pij_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "\u001b[1m4623/4623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.4625 - val_loss: 0.3827\n",
      "Epoch 2/500\n",
      "\u001b[1m3671/4623\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.4003"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m ranknet \u001b[38;5;241m=\u001b[39m RankNet()\n\u001b[0;32m      4\u001b[0m ranknet\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mranknet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxi_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxj_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpij_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxi_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxj_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpij_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rados\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\rados\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[0;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[0;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[1;32mc:\\Users\\rados\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\rados\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\rados\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rados\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rados\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\rados\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\rados\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rados\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1515\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\rados\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model using compile and fit\n",
    "\n",
    "ranknet = RankNet()\n",
    "ranknet.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "history = ranknet.fit([xi_train, xj_train], pij_train, epochs=500, batch_size=2, validation_data=([xi_test, xj_test], pij_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function for plotting loss\n",
    "def plot_metrics(train_metric, val_metric=None, metric_name=None, title=None, ylim=5):\n",
    "    plt.title(title)\n",
    "    plt.ylim(0,ylim)\n",
    "    plt.plot(train_metric,color='blue',label=metric_name)\n",
    "    if val_metric is not None: plt.plot(val_metric,color='green',label='val_' + metric_name)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "# plot loss history\n",
    "plot_metrics(history.history['loss'], history.history['val_loss'], \"Loss\", \"Loss\", ylim=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ranking(model, docks):\n",
    "    \"\"\"\n",
    "    Predict the ranking of docks using a trained RankNet model.\n",
    "    \n",
    "    Args:\n",
    "        model (RankNet): A trained RankNet model.\n",
    "        docks (np.array): A 2D numpy array where each row represents a dock's features.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: A NumPy array representing the predicted ranking of docks.\n",
    "    \"\"\"\n",
    "    # Number of docks\n",
    "    n_docks = docks.shape[0]\n",
    "    \n",
    "    # Generate all pairs of docks\n",
    "    dock_indices = np.arange(n_docks)\n",
    "    dock_pairs = np.array(list(combinations(dock_indices, 2)))\n",
    "    \n",
    "    # Prepare input arrays for model prediction\n",
    "    xi = docks[dock_pairs[:, 0]]\n",
    "    xj = docks[dock_pairs[:, 1]]\n",
    "    \n",
    "    # Predict pairwise preferences\n",
    "    pairwise_preds = model.predict([xi, xj])\n",
    "    \n",
    "    # Initialize score array\n",
    "    scores = np.zeros(n_docks)\n",
    "    \n",
    "    # Aggregate pairwise predictions into scores\n",
    "    for (i, j), pred in zip(dock_pairs, pairwise_preds):\n",
    "        if pred > 0.5:  # i is preferred over j\n",
    "            scores[i] += 1\n",
    "        else:           # j is preferred over i\n",
    "            scores[j] += 1\n",
    "    \n",
    "    # Sort docks by their scores in descending order\n",
    "    ranked_indices = np.argsort(-scores)  # Descending order\n",
    "    \n",
    "    return ranked_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 117ms/step"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_results = pd.DataFrame(columns = [\"data\", \"pred\"])\n",
    "\n",
    "for q in np.unique(query):\n",
    "    query_idx = np.where(query == q)[0]\n",
    "    ranking = predict_ranking(ranknet, doc_features[query_idx])\n",
    "    comparison = np.stack((ranking, doc_scores[query_idx]), axis = 1)\n",
    "    temp = pd.DataFrame(comparison, columns = [\"data\", \"pred\"])\n",
    "    df_results = pd.concat((df_results, temp))\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.01400000e+03, -2.67355573e-01,  1.38843029e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.50000000e+01],\n",
       "       [ 2.01400000e+03, -2.67355573e-01,  1.38843029e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.50000000e+01],\n",
       "       [ 2.01400000e+03, -2.67355573e-01,  1.38843029e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  7.50000000e+01],\n",
       "       ...,\n",
       "       [ 2.01400000e+03, -6.98767652e-02, -3.76303535e-01, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  7.50000000e+01],\n",
       "       [ 2.01400000e+03, -6.98767652e-02, -3.76303535e-01, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  7.50000000e+01],\n",
       "       [ 2.01400000e+03, -6.98767652e-02, -3.76303535e-01, ...,\n",
       "         0.00000000e+00,  1.00000000e+00,  7.50000000e+01]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_results.to_excel(\"results.xlsx\")\n",
    "dock_indices = np.arange(10)\n",
    "dock_pairs = np.array(list(combinations(dock_indices, 2)))\n",
    "temp = xi[dock_pairs[:, 0]]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.10324178],\n",
       "       [0.47266066],\n",
       "       [0.03913599],\n",
       "       [0.09474443],\n",
       "       [0.24619338],\n",
       "       [0.06296633],\n",
       "       [0.05359108],\n",
       "       [0.8861744 ],\n",
       "       [0.26132208]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_preds = ranknet_model.predict([xi[0:9,:], xj[0:9,:]])\n",
    "pairwise_preds\n",
    "\n",
    "# [i.shape for i in [xi[0:1,:], xj[0:1,:]]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
