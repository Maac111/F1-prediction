{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, activations, losses, Model, Input\n",
    "from tensorflow.nn import leaky_relu\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from tensorflow.keras.utils import plot_model, Progbar\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# model architecture\n",
    "class RankNet(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense = [layers.Dense(16, activation=leaky_relu), layers.Dense(8, activation=leaky_relu)]\n",
    "        self.o = layers.Dense(1, activation='linear')\n",
    "        self.oi_minus_oj = layers.Subtract()\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        xi, xj = inputs\n",
    "        densei = self.dense[0](xi)\n",
    "        densej = self.dense[0](xj)\n",
    "        for dense in self.dense[1:]:\n",
    "            densei = dense(densei)\n",
    "            densej = dense(densej)\n",
    "        oi = self.o(densei)\n",
    "        oj= self.o(densej)\n",
    "        oij = self.oi_minus_oj([oi, oj])\n",
    "        output = layers.Activation('sigmoid')(oij)\n",
    "        return output\n",
    "    \n",
    "    def build_graph(self):\n",
    "        x = [Input(shape=(10)), Input(shape=(10))]\n",
    "        return Model(inputs=x, outputs=self.call(x))\n",
    "    \n",
    "def predict_ranking(model, docks):\n",
    "    \"\"\"\n",
    "    Predict the ranking of docks using a trained RankNet model.\n",
    "    \n",
    "    Args:\n",
    "        model (RankNet): A trained RankNet model.\n",
    "        docks (np.array): A 2D numpy array where each row represents a dock's features.\n",
    "    \n",
    "    Returns:\n",
    "        List[int]: The indices of the docks sorted by their predicted ranking.\n",
    "    \"\"\"\n",
    "    # Number of docks\n",
    "    n_docks = docks.shape[0]\n",
    "    \n",
    "    # Generate all pairs of docks\n",
    "    dock_indices = list(range(n_docks))\n",
    "    dock_pairs = list(combinations(dock_indices, 2))\n",
    "    \n",
    "    # Prepare input arrays for model prediction\n",
    "    xi = np.array([docks[i] for i, j in dock_pairs])\n",
    "    xj = np.array([docks[j] for i, j in dock_pairs])\n",
    "    \n",
    "    # Predict pairwise preferences\n",
    "    pairwise_preds = model.predict([xi, xj])\n",
    "    \n",
    "    # Initialize score dictionary\n",
    "    scores = {i: 0 for i in dock_indices}\n",
    "    \n",
    "    # Aggregate pairwise predictions into scores\n",
    "    for (i, j), pred in zip(dock_pairs, pairwise_preds):\n",
    "        if pred > 0.5:  # i is preferred over j\n",
    "            scores[i] += 1\n",
    "        else:           # j is preferred over i\n",
    "            scores[j] += 1\n",
    "    \n",
    "    # Sort docks by their scores in descending order\n",
    "    ranked_indices = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)\n",
    "    \n",
    "    return ranked_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# generate data\n",
    "nb_query = 20\n",
    "### in each query number of docs can be diffrent\n",
    "query = np.array([i+1 for i in range(nb_query) for x in range(10)])\n",
    "### for each doc we can take some random features\n",
    "doc_features = np.random.random((len(query), 10))\n",
    "\n",
    "doc_scores = []\n",
    "\n",
    "# Generate and store shuffled ranks for each query\n",
    "for q in range(nb_query):\n",
    "    ranks = np.arange(1, 11).astype(np.float32)\n",
    "    np.random.shuffle(ranks)\n",
    "    doc_scores.append(ranks)\n",
    "\n",
    "# Convert the list of arrays to a NumPy array\n",
    "doc_scores = np.concatenate(doc_scores)\n",
    "\n",
    "# put data into pairs\n",
    "xi = []\n",
    "xj = []\n",
    "pij = []\n",
    "pair_id = []\n",
    "pair_query_id = []\n",
    "### for each query we must create all pairs\n",
    "for q in np.unique(query):\n",
    "    query_idx = np.where(query == q)[0]\n",
    "    # print(query_idx)\n",
    "    for pair_idx in combinations(query_idx, 2):\n",
    "        pair_query_id.append(q)\n",
    "        \n",
    "        pair_id.append(pair_idx)\n",
    "        i = pair_idx[0]\n",
    "        j = pair_idx[1]\n",
    "        xi.append(doc_features[i]) # features of first doc in pair\n",
    "        xj.append(doc_features[j]) # features of second doc in pair\n",
    "        \n",
    "        \n",
    "        if doc_scores[i] == doc_scores[j]:\n",
    "            _pij = 0.5\n",
    "        elif doc_scores[i] > doc_scores[j]:\n",
    "            _pij = 1\n",
    "        else: \n",
    "            _pij = 0\n",
    "        pij.append(_pij)\n",
    "        \n",
    "xi = np.array(xi)\n",
    "xj = np.array(xj)\n",
    "pij = np.array(pij)\n",
    "pair_query_id = np.array(pair_query_id)\n",
    "\n",
    "xi_train, xi_test, xj_train, xj_test, pij_train, pij_test, pair_id_train, pair_id_test = train_test_split(\n",
    "    xi, xj, pij, pair_id, test_size=0.2, stratify=pair_query_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.,  7., 10.,  6.,  2.,  3.,  4.,  9.,  1.,  5.,  5.,  7.,  3.,\n",
       "        2.,  6.,  9.,  8., 10.,  4.,  1.,  6., 10.,  1.,  7.,  8.,  4.,\n",
       "        2.,  5.,  9.,  3.,  7.,  4.,  9., 10.,  5.,  2.,  1.,  8.,  6.,\n",
       "        3.,  4.,  7.,  6.,  9.,  3.,  8.,  5.,  1., 10.,  2.,  6.,  8.,\n",
       "        7.,  9.,  3.,  4.,  1., 10.,  5.,  2.,  9.,  7.,  5.,  1.,  2.,\n",
       "        3.,  6.,  8.,  4., 10.,  8.,  1., 10.,  9.,  4.,  2.,  3.,  6.,\n",
       "        7.,  5.,  4.,  5.,  2.,  7.,  6.,  3., 10.,  9.,  8.,  1.,  8.,\n",
       "        7.,  4., 10.,  3.,  2.,  1.,  9.,  6.,  5.,  6., 10.,  3.,  2.,\n",
       "        7.,  8.,  4.,  5.,  1.,  9.,  7.,  8., 10.,  5.,  3.,  4.,  1.,\n",
       "        2.,  6.,  9.,  1.,  8.,  4.,  3.,  2.,  5., 10.,  6.,  7.,  9.,\n",
       "        9.,  8.,  1.,  7.,  2.,  3.,  5.,  4., 10.,  6.,  1.,  2.,  7.,\n",
       "        5.,  3.,  4.,  9.,  8., 10.,  6.,  5.,  8.,  6.,  2.,  1.,  4.,\n",
       "        7.,  3., 10.,  9.,  1., 10.,  6.,  4.,  7.,  3.,  8.,  2.,  5.,\n",
       "        9.,  4.,  7.,  9.,  2.,  5.,  8., 10.,  6.,  1.,  3.,  9.,  6.,\n",
       "        4.,  1.,  7.,  8.,  3., 10.,  2.,  5.,  5.,  6.,  2.,  1., 10.,\n",
       "        9.,  7.,  4.,  3.,  8.], dtype=float32)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.6948 - val_loss: 0.6977\n",
      "Epoch 2/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - loss: 0.6885 - val_loss: 0.6944\n",
      "Epoch 3/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751us/step - loss: 0.6873 - val_loss: 0.6924\n",
      "Epoch 4/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - loss: 0.6815 - val_loss: 0.6889\n",
      "Epoch 5/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - loss: 0.6781 - val_loss: 0.6859\n",
      "Epoch 6/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 750us/step - loss: 0.6685 - val_loss: 0.6859\n",
      "Epoch 7/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6708 - val_loss: 0.6835\n",
      "Epoch 8/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 791us/step - loss: 0.6613 - val_loss: 0.6840\n",
      "Epoch 9/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - loss: 0.6641 - val_loss: 0.6942\n",
      "Epoch 10/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - loss: 0.6684 - val_loss: 0.6789\n",
      "Epoch 11/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947us/step - loss: 0.6537 - val_loss: 0.6832\n",
      "Epoch 12/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832us/step - loss: 0.6621 - val_loss: 0.6784\n",
      "Epoch 13/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6444 - val_loss: 0.6730\n",
      "Epoch 14/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - loss: 0.6305 - val_loss: 0.6737\n",
      "Epoch 15/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 993us/step - loss: 0.6364 - val_loss: 0.6754\n",
      "Epoch 16/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - loss: 0.6319 - val_loss: 0.6641\n",
      "Epoch 17/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 831us/step - loss: 0.6389 - val_loss: 0.6740\n",
      "Epoch 18/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 823us/step - loss: 0.6254 - val_loss: 0.6584\n",
      "Epoch 19/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6229 - val_loss: 0.6658\n",
      "Epoch 20/20\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.6286 - val_loss: 0.6724\n"
     ]
    }
   ],
   "source": [
    "# train model using compile and fit\n",
    "ranknet = RankNet()\n",
    "ranknet.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "history = ranknet.fit([xi_train, xj_train], pij_train, epochs=20, batch_size=1, validation_data=([xi_test, xj_test], pij_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# function for plotting loss\n",
    "def plot_metrics(train_metric, val_metric=None, metric_name=None, title=None, ylim=5):\n",
    "    plt.title(title)\n",
    "    plt.ylim(0,ylim)\n",
    "    plt.plot(train_metric,color='blue',label=metric_name)\n",
    "    if val_metric is not None: plt.plot(val_metric,color='green',label='val_' + metric_name)\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "# plot loss history\n",
    "plot_metrics(history.history['loss'], history.history['val_loss'], \"Loss\", \"Loss\", ylim=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ranking(model, docks):\n",
    "    \"\"\"\n",
    "    Predict the ranking of docks using a trained RankNet model.\n",
    "    \n",
    "    Args:\n",
    "        model (RankNet): A trained RankNet model.\n",
    "        docks (np.array): A 2D numpy array where each row represents a dock's features.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: A NumPy array representing the predicted ranking of docks.\n",
    "    \"\"\"\n",
    "    # Number of docks\n",
    "    n_docks = docks.shape[0]\n",
    "    \n",
    "    # Generate all pairs of docks\n",
    "    dock_indices = np.arange(n_docks)\n",
    "    dock_pairs = np.array(list(combinations(dock_indices, 2)))\n",
    "    \n",
    "    # Prepare input arrays for model prediction\n",
    "    xi = docks[dock_pairs[:, 0]]\n",
    "    xj = docks[dock_pairs[:, 1]]\n",
    "    \n",
    "    # Predict pairwise preferences\n",
    "    pairwise_preds = model.predict([xi, xj])\n",
    "    \n",
    "    # Initialize score array\n",
    "    scores = np.zeros(n_docks)\n",
    "    \n",
    "    # Aggregate pairwise predictions into scores\n",
    "    for (i, j), pred in zip(dock_pairs, pairwise_preds):\n",
    "        if pred > 0.5:  # i is preferred over j\n",
    "            scores[i] += 1\n",
    "        else:           # j is preferred over i\n",
    "            scores[j] += 1\n",
    "    \n",
    "    # Sort docks by their scores in descending order\n",
    "    ranked_indices = np.argsort(-scores)  # Descending order\n",
    "    \n",
    "    return ranked_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "[[ 8.  8.]\n",
      " [ 2.  7.]\n",
      " [ 3. 10.]\n",
      " [ 0.  6.]\n",
      " [ 5.  2.]\n",
      " [ 9.  3.]\n",
      " [ 1.  4.]\n",
      " [ 7.  9.]\n",
      " [ 6.  1.]\n",
      " [ 4.  5.]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# # Make predictions on the test data\n",
    "# driver_a = np.ones((2,10))\n",
    "# driver_b = np.ones((2,10)) + -1\n",
    "# predictions = ranknet.predict([driver_a, driver_b])\n",
    "# predictions\n",
    "\n",
    "docks = np.random.rand(10, 10) \n",
    "# print(docks)\n",
    "# doc_scores\n",
    "# query\n",
    "# docks\n",
    "\n",
    "# ranking = predict_ranking(ranknet, docks)\n",
    "# ranking\n",
    "df_results = pd.DataFrame()\n",
    "\n",
    "for q in np.unique(query):\n",
    "    if q != 1:\n",
    "        continue\n",
    "    query_idx = np.where(query == q)[0]\n",
    "    ranking = predict_ranking(ranknet, doc_features[query_idx])\n",
    "    comparison = np.stack((ranking, doc_scores[query_idx]), axis = 1)\n",
    "    print(comparison)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 10)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410, 10)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xj_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.993847</td>\n",
       "      <td>0.319057</td>\n",
       "      <td>0.097252</td>\n",
       "      <td>0.788216</td>\n",
       "      <td>0.084758</td>\n",
       "      <td>0.520777</td>\n",
       "      <td>0.073787</td>\n",
       "      <td>0.065928</td>\n",
       "      <td>0.345493</td>\n",
       "      <td>0.050809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.440636</td>\n",
       "      <td>0.539315</td>\n",
       "      <td>0.572966</td>\n",
       "      <td>0.814121</td>\n",
       "      <td>0.102193</td>\n",
       "      <td>0.623215</td>\n",
       "      <td>0.594918</td>\n",
       "      <td>0.638757</td>\n",
       "      <td>0.721550</td>\n",
       "      <td>0.472905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.245963</td>\n",
       "      <td>0.585991</td>\n",
       "      <td>0.170838</td>\n",
       "      <td>0.818544</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>0.609022</td>\n",
       "      <td>0.178915</td>\n",
       "      <td>0.012006</td>\n",
       "      <td>0.234004</td>\n",
       "      <td>0.969845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.261121</td>\n",
       "      <td>0.589638</td>\n",
       "      <td>0.937703</td>\n",
       "      <td>0.460541</td>\n",
       "      <td>0.896647</td>\n",
       "      <td>0.436451</td>\n",
       "      <td>0.664211</td>\n",
       "      <td>0.208750</td>\n",
       "      <td>0.669538</td>\n",
       "      <td>0.926470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.127805</td>\n",
       "      <td>0.184709</td>\n",
       "      <td>0.803842</td>\n",
       "      <td>0.976870</td>\n",
       "      <td>0.420374</td>\n",
       "      <td>0.016633</td>\n",
       "      <td>0.644816</td>\n",
       "      <td>0.035458</td>\n",
       "      <td>0.207999</td>\n",
       "      <td>0.924188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>0.336772</td>\n",
       "      <td>0.599577</td>\n",
       "      <td>0.219799</td>\n",
       "      <td>0.213485</td>\n",
       "      <td>0.909376</td>\n",
       "      <td>0.735869</td>\n",
       "      <td>0.597533</td>\n",
       "      <td>0.320638</td>\n",
       "      <td>0.902255</td>\n",
       "      <td>0.420488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>0.644840</td>\n",
       "      <td>0.893548</td>\n",
       "      <td>0.650571</td>\n",
       "      <td>0.373439</td>\n",
       "      <td>0.610802</td>\n",
       "      <td>0.886661</td>\n",
       "      <td>0.995396</td>\n",
       "      <td>0.635289</td>\n",
       "      <td>0.797047</td>\n",
       "      <td>0.562709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.535393</td>\n",
       "      <td>0.282453</td>\n",
       "      <td>0.173462</td>\n",
       "      <td>0.424132</td>\n",
       "      <td>0.918610</td>\n",
       "      <td>0.954581</td>\n",
       "      <td>0.534859</td>\n",
       "      <td>0.114128</td>\n",
       "      <td>0.865750</td>\n",
       "      <td>0.992649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>0.780753</td>\n",
       "      <td>0.731565</td>\n",
       "      <td>0.749342</td>\n",
       "      <td>0.757376</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.197655</td>\n",
       "      <td>0.765120</td>\n",
       "      <td>0.630472</td>\n",
       "      <td>0.379705</td>\n",
       "      <td>0.487883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>0.956583</td>\n",
       "      <td>0.487301</td>\n",
       "      <td>0.959581</td>\n",
       "      <td>0.897285</td>\n",
       "      <td>0.298725</td>\n",
       "      <td>0.632442</td>\n",
       "      <td>0.610279</td>\n",
       "      <td>0.061954</td>\n",
       "      <td>0.091556</td>\n",
       "      <td>0.452018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2         3         4         5         6         7  \\\n",
       "0    0.993847  0.319057  0.097252  0.788216  0.084758  0.520777  0.073787   \n",
       "1    0.440636  0.539315  0.572966  0.814121  0.102193  0.623215  0.594918   \n",
       "2    0.245963  0.585991  0.170838  0.818544  0.092318  0.609022  0.178915   \n",
       "3    0.261121  0.589638  0.937703  0.460541  0.896647  0.436451  0.664211   \n",
       "4    0.127805  0.184709  0.803842  0.976870  0.420374  0.016633  0.644816   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "772  0.336772  0.599577  0.219799  0.213485  0.909376  0.735869  0.597533   \n",
       "781  0.644840  0.893548  0.650571  0.373439  0.610802  0.886661  0.995396   \n",
       "799  0.535393  0.282453  0.173462  0.424132  0.918610  0.954581  0.534859   \n",
       "801  0.780753  0.731565  0.749342  0.757376  0.596491  0.197655  0.765120   \n",
       "810  0.956583  0.487301  0.959581  0.897285  0.298725  0.632442  0.610279   \n",
       "\n",
       "            8         9        10  \n",
       "0    0.065928  0.345493  0.050809  \n",
       "1    0.638757  0.721550  0.472905  \n",
       "2    0.012006  0.234004  0.969845  \n",
       "3    0.208750  0.669538  0.926470  \n",
       "4    0.035458  0.207999  0.924188  \n",
       "..        ...       ...       ...  \n",
       "772  0.320638  0.902255  0.420488  \n",
       "781  0.635289  0.797047  0.562709  \n",
       "799  0.114128  0.865750  0.992649  \n",
       "801  0.630472  0.379705  0.487883  \n",
       "810  0.061954  0.091556  0.452018  \n",
       "\n",
       "[227 rows x 10 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_all_test = np.vstack((xi_test, xj_test))\n",
    "x_all_test \n",
    "check_df = pd.DataFrame(x_all_test, columns=[str(i) for i in range(1, 11)])\n",
    "check_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 6., 5., 8., 9., 9., 5., 8., 3., 8., 3., 1., 1., 9., 4., 8., 4.,\n",
       "       6., 8., 0., 4., 6., 9., 0., 7., 2., 1., 0., 3., 2., 3., 5., 5., 5.,\n",
       "       0., 6., 1., 0., 1., 8., 1., 2., 6., 4., 1., 1., 3., 2., 1., 7., 9.,\n",
       "       7., 3., 7., 0., 6., 2., 0., 8., 3., 3., 4., 5., 7., 5., 2., 7., 6.,\n",
       "       5., 6., 5., 5., 8., 7., 1., 0., 6., 2., 9., 0., 1., 0., 0., 8., 6.,\n",
       "       2., 4., 4., 7., 7., 5., 0., 3., 5., 4., 9., 0., 6., 1., 9., 1., 6.,\n",
       "       4., 5., 3., 0., 7., 9., 4., 4., 9., 3., 5., 2., 6., 2., 6., 8., 9.,\n",
       "       6., 1., 9., 6., 0., 3., 1., 1., 0., 3., 1., 7., 9., 5., 7., 2., 9.,\n",
       "       5., 2., 1., 4., 1., 5., 1., 8., 0., 1., 1., 3., 4., 1., 5., 4., 3.,\n",
       "       4., 5., 1., 1., 8., 3., 2., 4., 3., 9., 2., 6., 0., 1., 3., 6., 6.,\n",
       "       2., 6., 1., 1., 8., 9., 0., 1., 8., 5., 3., 1., 1., 2., 5., 5., 2.,\n",
       "       7., 4., 4., 4., 3., 5., 9., 1., 3., 2., 5., 0., 9.], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query\n",
    "doc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85065851, 0.76645938, 0.46262373, ..., 0.2487295 , 0.54740904,\n",
       "        0.75784825],\n",
       "       [0.54802548, 0.96443264, 0.69201354, ..., 0.82412754, 0.19170757,\n",
       "        0.01766016],\n",
       "       [0.80006893, 0.13373313, 0.4116677 , ..., 0.94887944, 0.58042506,\n",
       "        0.00518184],\n",
       "       ...,\n",
       "       [0.73633214, 0.81102309, 0.57044815, ..., 0.164273  , 0.37554393,\n",
       "        0.7822381 ],\n",
       "       [0.14265774, 0.26637338, 0.62889741, ..., 0.57457377, 0.99311713,\n",
       "        0.75633511],\n",
       "       [0.69297492, 0.42638288, 0.23095235, ..., 0.46151622, 0.19218285,\n",
       "        0.79694347]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
